{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8215933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import tkinter as tk\n",
    "from tkinter import Tk, Label, Entry, Button, filedialog, messagebox, Frame\n",
    "from tkinter import ttk\n",
    "import shutil\n",
    "import threading\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0ce2b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATASET_PATH = 'dataset'\n",
    "TRAINER_PATH = 'trainer'\n",
    "MODEL_FILE = os.path.join(TRAINER_PATH, 'trainer.yml')\n",
    "ATTENDANCE_FILE = 'attendance.csv'\n",
    "LOG_FILE = 'system_log.txt'\n",
    "\n",
    "# Ensure necessary directories exist\n",
    "os.makedirs(DATASET_PATH, exist_ok=True)\n",
    "os.makedirs(TRAINER_PATH, exist_ok=True)\n",
    "\n",
    "# Initialize Haar Cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "if face_cascade.empty():\n",
    "    raise Exception(\"Failed to load Haar Cascade classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8106d648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for logging\n",
    "def log_activity(message):\n",
    "    \"\"\"Log activity with timestamp to the log file\"\"\"\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    log_message = f\"[{timestamp}] {message}\\n\"\n",
    "    \n",
    "    try:\n",
    "        with open(LOG_FILE, 'a') as f:\n",
    "            f.write(log_message)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to write to log file: {str(e)}\")\n",
    "    \n",
    "    print(log_message.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3fa1f96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVAttendanceSystem:\n",
    "    def __init__(self, dataset_path=DATASET_PATH, model_file=MODEL_FILE, attendance_file=ATTENDANCE_FILE):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.model_file = model_file\n",
    "        self.attendance_file = attendance_file\n",
    "        self.face_cascade = face_cascade\n",
    "        try:\n",
    "            self.recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "        except AttributeError:\n",
    "            raise Exception(\"OpenCV face recognition module not available. Ensure opencv-contrib-python is installed.\")\n",
    "        self.labels = {}\n",
    "        self.confidence_threshold = 80  # Default threshold for face recognition\n",
    "        self.status_callback = None\n",
    "        self.attendance_thread = None\n",
    "        self.stop_flag = False\n",
    "\n",
    "    def set_status_callback(self, callback):\n",
    "        \"\"\"Set callback function for status updates\"\"\"\n",
    "        self.status_callback = callback\n",
    "\n",
    "    def update_status(self, message):\n",
    "        \"\"\"Update status through callback if available\"\"\"\n",
    "        if self.status_callback:\n",
    "            self.status_callback(message)\n",
    "        log_activity(message)\n",
    "\n",
    "    def collect_training_data(self):\n",
    "        \"\"\"Collect training data from the dataset directory\"\"\"\n",
    "        faces = []\n",
    "        ids = []\n",
    "        label_id = 0\n",
    "        self.labels = {}\n",
    "        \n",
    "        # Check if dataset path exists\n",
    "        if not os.path.exists(self.dataset_path):\n",
    "            self.update_status(\"[ERROR] Dataset path does not exist.\")\n",
    "            return faces, ids\n",
    "        \n",
    "        # Iterate through each person's directory\n",
    "        for person_name in os.listdir(self.dataset_path):\n",
    "            person_dir = os.path.join(self.dataset_path, person_name)\n",
    "            if os.path.isdir(person_dir):\n",
    "                self.labels[label_id] = person_name\n",
    "                image_count = 0\n",
    "                \n",
    "                # Process each image in the person's directory\n",
    "                for img_file in os.listdir(person_dir):\n",
    "                    if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        continue\n",
    "                        \n",
    "                    img_path = os.path.join(person_dir, img_file)\n",
    "                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    \n",
    "                    if img is None:\n",
    "                        self.update_status(f\"[WARNING] Could not read image: {img_path}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Resize image for consistency\n",
    "                    img = cv2.resize(img, (100, 100))\n",
    "                    faces.append(img)\n",
    "                    ids.append(label_id)\n",
    "                    image_count += 1\n",
    "                \n",
    "                self.update_status(f\"[INFO] Collected {image_count} images for {person_name}\")\n",
    "                label_id += 1\n",
    "        \n",
    "        # Save labels mapping to file for later use\n",
    "        try:\n",
    "            with open(os.path.join(TRAINER_PATH, 'labels.csv'), 'w', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(['ID', 'Name'])\n",
    "                for label_id, name in self.labels.items():\n",
    "                    writer.writerow([label_id, name])\n",
    "        except Exception as e:\n",
    "            self.update_status(f\"[ERROR] Failed to save labels: {str(e)}\")\n",
    "        \n",
    "        return faces, ids\n",
    "\n",
    "    def train_model(self):\n",
    "        \"\"\"Train the face recognition model\"\"\"\n",
    "        self.update_status(\"[INFO] Training model...\")\n",
    "        \n",
    "        faces, ids = self.collect_training_data()\n",
    "        \n",
    "        if len(faces) == 0:\n",
    "            self.update_status(\"[ERROR] No training data found.\")\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            self.recognizer.train(faces, np.array(ids))\n",
    "            self.recognizer.save(self.model_file)\n",
    "            self.update_status(f\"[INFO] Model trained successfully with {len(faces)} images.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            self.update_status(f\"[ERROR] Training failed: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"Load the trained model and labels\"\"\"\n",
    "        try:\n",
    "            # Load the model file\n",
    "            if os.path.exists(self.model_file):\n",
    "                self.recognizer.read(self.model_file)\n",
    "                \n",
    "                # Load labels from file\n",
    "                self.labels = {}\n",
    "                labels_file = os.path.join(TRAINER_PATH, 'labels.csv')\n",
    "                \n",
    "                if os.path.exists(labels_file):\n",
    "                    df = pd.read_csv(labels_file)\n",
    "                    for _, row in df.iterrows():\n",
    "                        self.labels[row['ID']] = row['Name']\n",
    "                    \n",
    "                    self.update_status(\"[INFO] Model and labels loaded successfully.\")\n",
    "                    return True\n",
    "                else:\n",
    "                    self.update_status(\"[ERROR] Labels file not found.\")\n",
    "                    return False\n",
    "            else:\n",
    "                self.update_status(\"[ERROR] Model file not found.\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            self.update_status(f\"[ERROR] Failed to load model: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def mark_attendance(self, name):\n",
    "        \"\"\"Mark attendance for a recognized person\"\"\"\n",
    "        now = datetime.now()\n",
    "        date = now.strftime('%Y-%m-%d')\n",
    "        time_str = now.strftime('%H:%M:%S')\n",
    "        \n",
    "        # Create DataFrame for the new entry\n",
    "        df = pd.DataFrame([[name, date, time_str]], columns=['Name', 'Date', 'Time'])\n",
    "        \n",
    "        # Check if attendance file exists\n",
    "        if os.path.exists(self.attendance_file):\n",
    "            # Check if this person was already marked today\n",
    "            try:\n",
    "                existing_df = pd.read_csv(self.attendance_file)\n",
    "                today_records = existing_df[(existing_df['Name'] == name) & (existing_df['Date'] == date)]\n",
    "                \n",
    "                if len(today_records) == 0:\n",
    "                    # Append to existing file if person not already marked today\n",
    "                    df.to_csv(self.attendance_file, mode='a', header=False, index=False)\n",
    "                    self.update_status(f\"[INFO] Marked attendance for {name}\")\n",
    "                    return True\n",
    "                else:\n",
    "                    self.update_status(f\"[INFO] {name} already marked for today\")\n",
    "                    return False\n",
    "            except Exception as e:\n",
    "                self.update_status(f\"[ERROR] Failed to read attendance file: {str(e)}\")\n",
    "                return False\n",
    "        else:\n",
    "            # Create new file if it doesn't exist\n",
    "            try:\n",
    "                df.to_csv(self.attendance_file, index=False)\n",
    "                self.update_status(f\"[INFO] Created attendance file and marked {name}\")\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                self.update_status(f\"[ERROR] Failed to create attendance file: {str(e)}\")\n",
    "                return False\n",
    "    \n",
    "    def set_confidence_threshold(self, threshold):\n",
    "        \"\"\"Set the confidence threshold for face recognition\"\"\"\n",
    "        try:\n",
    "            threshold = float(threshold)\n",
    "            if 0 <= threshold <= 100:\n",
    "                self.confidence_threshold = threshold\n",
    "                self.update_status(f\"[INFO] Recognition threshold set to {threshold}\")\n",
    "                return True\n",
    "            else:\n",
    "                self.update_status(\"[ERROR] Threshold must be between 0 and 100\")\n",
    "                return False\n",
    "        except ValueError:\n",
    "            self.update_status(\"[ERROR] Invalid threshold value\")\n",
    "            return False\n",
    "\n",
    "    def run_real_time_attendance(self):\n",
    "        \"\"\"Start real-time attendance monitoring in a separate thread\"\"\"\n",
    "        if self.attendance_thread and self.attendance_thread.is_alive():\n",
    "            self.update_status(\"[INFO] Attendance monitoring is already running\")\n",
    "            return\n",
    "        \n",
    "        # Reset stop flag\n",
    "        self.stop_flag = False\n",
    "        \n",
    "        # Start attendance monitoring in a new thread\n",
    "        self.attendance_thread = threading.Thread(target=self._attendance_thread)\n",
    "        self.attendance_thread.daemon = True\n",
    "        self.attendance_thread.start()\n",
    "        \n",
    "        self.update_status(\"[INFO] Started real-time attendance monitoring\")\n",
    "    \n",
    "    def stop_attendance(self):\n",
    "        \"\"\"Stop the attendance monitoring thread\"\"\"\n",
    "        if self.attendance_thread and self.attendance_thread.is_alive():\n",
    "            self.stop_flag = True\n",
    "            self.update_status(\"[INFO] Stopping attendance monitoring...\")\n",
    "        else:\n",
    "            self.update_status(\"[INFO] Attendance monitoring is not running\")\n",
    "    \n",
    "    def _attendance_thread(self):\n",
    "        \"\"\"Thread function for real-time attendance monitoring\"\"\"\n",
    "        if not self.load_model():\n",
    "            self.update_status(\"[ERROR] Could not load model. Please train the model first.\")\n",
    "            return\n",
    "        \n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            self.update_status(\"[ERROR] Could not open webcam\")\n",
    "            return\n",
    "        \n",
    "        # Set for tracking recognized people in current session\n",
    "        recognized = set()\n",
    "        \n",
    "        try:\n",
    "            while not self.stop_flag:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    self.update_status(\"[ERROR] Failed to capture frame from webcam\")\n",
    "                    break\n",
    "                \n",
    "                # Convert to grayscale for face detection\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                # Apply histogram equalization for better contrast\n",
    "                gray = cv2.equalizeHist(gray)\n",
    "                \n",
    "                # Detect faces\n",
    "                faces = self.face_cascade.detectMultiScale(gray, 1.3, 5, minSize=(30, 30))\n",
    "                \n",
    "                for (x, y, w, h) in faces:\n",
    "                    # Extract and preprocess face\n",
    "                    face = gray[y:y+h, x:x+w]\n",
    "                    face = cv2.resize(face, (100, 100))\n",
    "                    \n",
    "                    try:\n",
    "                        # Predict label for the face\n",
    "                        label_id, confidence = self.recognizer.predict(face)\n",
    "                        \n",
    "                        # Check if prediction is confident enough\n",
    "                        if confidence < self.confidence_threshold:\n",
    "                            name = self.labels.get(label_id, \"Unknown\")\n",
    "                            \n",
    "                            # Mark attendance if not already recognized in this session\n",
    "                            if name != \"Unknown\" and name not in recognized:\n",
    "                                if self.mark_attendance(name):\n",
    "                                    recognized.add(name)\n",
    "                            \n",
    "                            # Draw rectangle and label\n",
    "                            color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "                            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "                            label_text = f\"{name} ({int(confidence)})\" if name != \"Unknown\" else \"Unknown\"\n",
    "                            cv2.putText(frame, label_text, (x, y-10),\n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "                        else:\n",
    "                            # Unknown face\n",
    "                            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "                            cv2.putText(frame, \"Unknown\", (x, y-10),\n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                    except Exception as e:\n",
    "                        self.update_status(f\"[ERROR] Recognition error: {str(e)}\")\n",
    "                \n",
    "                # Display frame with annotations\n",
    "                cv2.imshow(\"Attendance System\", frame)\n",
    "                \n",
    "                # Check for key press (q to quit)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    self.stop_flag = True\n",
    "                    break\n",
    "                \n",
    "                # Small delay to reduce CPU usage\n",
    "                time.sleep(0.03)\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.update_status(f\"[ERROR] Attendance monitoring error: {str(e)}\")\n",
    "        finally:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            self.update_status(\"[INFO] Attendance monitoring stopped\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f86edeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_from_webcam(dataset_path, name, num_samples=10, delay=1.0, update_callback=None):\n",
    "    \"\"\"Capture face images from webcam for training dataset\"\"\"\n",
    "    if not name:\n",
    "        if update_callback:\n",
    "            update_callback(\"[ERROR] Please enter a valid name\")\n",
    "        return False\n",
    "\n",
    "    person_dir = os.path.join(dataset_path, name)\n",
    "    os.makedirs(person_dir, exist_ok=True)\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        if update_callback:\n",
    "            update_callback(\"[ERROR] Could not open webcam\")\n",
    "        return False\n",
    "    \n",
    "    count = 0\n",
    "    if update_callback:\n",
    "        update_callback(f\"[INFO] Capturing images for {name}...\")\n",
    "    \n",
    "    try:\n",
    "        while count < num_samples:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                continue\n",
    "            \n",
    "            # Convert to grayscale\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Apply histogram equalization\n",
    "            gray = cv2.equalizeHist(gray)\n",
    "            \n",
    "            # Display frame with rectangle guidance\n",
    "            height, width = frame.shape[:2]\n",
    "            center_x, center_y = width // 2, height // 2\n",
    "            offset = min(width, height) // 4\n",
    "            \n",
    "            # Draw positioning guide\n",
    "            cv2.rectangle(frame, \n",
    "                         (center_x - offset, center_y - offset), \n",
    "                         (center_x + offset, center_y + offset), \n",
    "                         (255, 255, 0), 2)\n",
    "            \n",
    "            # Display instructions\n",
    "            cv2.putText(frame, \"Position face in box\", (30, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Capturing: {count}/{num_samples}\", (30, 60), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            \n",
    "            # Show frame\n",
    "            cv2.imshow(\"Capture Face\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            # Press spacebar to capture, q to quit\n",
    "            if key == ord(' '):\n",
    "                # Detect faces\n",
    "                faces = face_cascade.detectMultiScale(gray, 1.3, 5, minSize=(30, 30))\n",
    "                \n",
    "                if len(faces) == 0:\n",
    "                    if update_callback:\n",
    "                        update_callback(\"[WARNING] No face detected. Please try again.\")\n",
    "                    continue\n",
    "                \n",
    "                # Take the largest face if multiple detected\n",
    "                if len(faces) > 1:\n",
    "                    faces = sorted(faces, key=lambda x: x[2] * x[3], reverse=True)\n",
    "                \n",
    "                (x, y, w, h) = faces[0]\n",
    "                \n",
    "                # Extract and save face\n",
    "                face = gray[y:y+h, x:x+w]\n",
    "                face = cv2.resize(face, (100, 100))\n",
    "                file_path = os.path.join(person_dir, f\"{count}.jpg\")\n",
    "                cv2.imwrite(file_path, face)\n",
    "                count += 1\n",
    "                \n",
    "                if update_callback:\n",
    "                    update_callback(f\"[INFO] Samples captured: {count}/{num_samples}\")\n",
    "                \n",
    "                # Small delay between captures\n",
    "                time.sleep(delay)\n",
    "            \n",
    "            elif key == ord('q'):\n",
    "                break\n",
    "    except Exception as e:\n",
    "        if update_callback:\n",
    "            update_callback(f\"[ERROR] Capture error: {str(e)}\")\n",
    "        return False\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    if count > 0:\n",
    "        if update_callback:\n",
    "            update_callback(f\"[INFO] Successfully captured {count} images for {name}\")\n",
    "        return True\n",
    "    else:\n",
    "        if update_callback:\n",
    "            update_callback(\"[ERROR] No images captured\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d85128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_external_images(dataset_path, name, status_callback=None):\n",
    "    \"\"\"Add and process external images for a person\"\"\"\n",
    "    if not name:\n",
    "        if status_callback:\n",
    "            status_callback(\"[ERROR] Please enter a valid name\")\n",
    "        return False\n",
    "\n",
    "    # Open file selection dialog\n",
    "    file_paths = filedialog.askopenfilenames(\n",
    "        title=\"Select Face Images\",\n",
    "        filetypes=[(\"Image Files\", \"*.jpg;*.jpeg;*.png\")]\n",
    "    )\n",
    "    \n",
    "    if not file_paths:\n",
    "        if status_callback:\n",
    "            status_callback(\"[INFO] No files selected\")\n",
    "        return False\n",
    "    \n",
    "    # Create person directory if it doesn't exist\n",
    "    person_dir = os.path.join(dataset_path, name)\n",
    "    os.makedirs(person_dir, exist_ok=True)\n",
    "    \n",
    "    # Count existing files to continue numbering\n",
    "    existing_files = [f for f in os.listdir(person_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    count = len(existing_files)\n",
    "    \n",
    "    # Process each selected file\n",
    "    success_count = 0\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            # Read image\n",
    "            img = cv2.imread(file_path)\n",
    "            if img is None:\n",
    "                if status_callback:\n",
    "                    status_callback(f\"[WARNING] Could not read file: {os.path.basename(file_path)}\")\n",
    "                continue\n",
    "            \n",
    "            # Convert to grayscale\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Apply histogram equalization\n",
    "            gray = cv2.equalizeHist(gray)\n",
    "            \n",
    "            # Detect faces\n",
    "            faces = face_cascade.detectMultiScale(gray, 1.3, 5, minSize=(30, 30))\n",
    "            \n",
    "            if len(faces) == 0:\n",
    "                if status_callback:\n",
    "                    status_callback(f\"[WARNING] No face detected in {os.path.basename(file_path)}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # Take the largest face if multiple detected\n",
    "            if len(faces) > 1:\n",
    "                faces = sorted(faces, key=lambda x: x[2] * x[3], reverse=True)\n",
    "                if status_callback:\n",
    "                    status_callback(f\"[INFO] Multiple faces detected in {os.path.basename(file_path)}. Using largest face.\")\n",
    "            \n",
    "            # Extract and save face\n",
    "            (x, y, w, h) = faces[0]\n",
    "            face = gray[y:y+h, x:x+w]\n",
    "            face_resized = cv2.resize(face, (100, 100))\n",
    "            \n",
    "            # Save processed face\n",
    "            img_name = os.path.join(person_dir, f\"{count}.jpg\")\n",
    "            cv2.imwrite(img_name, face_resized)\n",
    "            \n",
    "            if status_callback:\n",
    "                status_callback(f\"[INFO] Processed image: {os.path.basename(file_path)}\")\n",
    "            \n",
    "            count += 1\n",
    "            success_count += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            if status_callback:\n",
    "                status_callback(f\"[ERROR] Failed to process {os.path.basename(file_path)}: {str(e)}\")\n",
    "    \n",
    "    if status_callback:\n",
    "        status_callback(f\"[INFO] Successfully processed {success_count} of {len(file_paths)} images for {name}\")\n",
    "    \n",
    "    return success_count > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61b1ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_attendance(attendance_file):\n",
    "    \"\"\"Show attendance records in a new window\"\"\"\n",
    "    # Create a new window\n",
    "    attendance_window = tk.Toplevel()\n",
    "    attendance_window.title(\"Attendance Records\")\n",
    "    attendance_window.geometry(\"700x500\")\n",
    "    \n",
    "    # Create main frame\n",
    "    main_frame = tk.Frame(attendance_window)\n",
    "    main_frame.pack(fill=\"both\", expand=True, padx=10, pady=10)\n",
    "    \n",
    "    # Create top control frame\n",
    "    control_frame = tk.Frame(main_frame)\n",
    "    control_frame.pack(fill=\"x\", pady=(0, 10))\n",
    "    \n",
    "    # Add date filter\n",
    "    date_label = tk.Label(control_frame, text=\"Filter by date:\")\n",
    "    date_label.pack(side=\"left\", padx=(0, 5))\n",
    "    \n",
    "    date_var = tk.StringVar()\n",
    "    date_combobox = ttk.Combobox(control_frame, textvariable=date_var, width=15)\n",
    "    date_combobox.pack(side=\"left\", padx=(0, 10))\n",
    "    \n",
    "    # Add name filter\n",
    "    name_label = tk.Label(control_frame, text=\"Filter by name:\")\n",
    "    name_label.pack(side=\"left\", padx=(10, 5))\n",
    "    \n",
    "    name_var = tk.StringVar()\n",
    "    name_combobox = ttk.Combobox(control_frame, textvariable=name_var, width=15)\n",
    "    name_combobox.pack(side=\"left\")\n",
    "    \n",
    "    # Add search functionality\n",
    "    search_label = tk.Label(control_frame, text=\"Search:\")\n",
    "    search_label.pack(side=\"left\", padx=(10, 5))\n",
    "    \n",
    "    search_var = tk.StringVar()\n",
    "    search_entry = tk.Entry(control_frame, textvariable=search_var, width=15)\n",
    "    search_entry.pack(side=\"left\")\n",
    "    \n",
    "    # Add search button\n",
    "    search_button = tk.Button(control_frame, text=\"Search\", \n",
    "                             command=lambda: apply_filters(tree, attendance_file, date_var.get(), name_var.get(), search_var.get()))\n",
    "    search_button.pack(side=\"left\", padx=5)\n",
    "    \n",
    "    # Add reset button\n",
    "    reset_button = tk.Button(control_frame, text=\"Reset\", \n",
    "                            command=lambda: load_data(tree, attendance_file, date_combobox, name_combobox))\n",
    "    reset_button.pack(side=\"left\")\n",
    "    \n",
    "    # Create a frame for the treeview and scrollbars\n",
    "    tree_frame = tk.Frame(main_frame)\n",
    "    tree_frame.pack(fill=\"both\", expand=True)\n",
    "    \n",
    "    try:\n",
    "        # Check if attendance file exists\n",
    "        if not os.path.exists(attendance_file) or os.path.getsize(attendance_file) == 0:\n",
    "            empty_label = tk.Label(tree_frame, text=\"No attendance records found\", fg=\"gray\")\n",
    "            empty_label.pack(pady=50)\n",
    "            return\n",
    "        \n",
    "        # Create Treeview\n",
    "        tree = ttk.Treeview(tree_frame)\n",
    "        \n",
    "        # Add vertical scrollbar\n",
    "        vsb = ttk.Scrollbar(tree_frame, orient=\"vertical\", command=tree.yview)\n",
    "        vsb.pack(side=\"right\", fill=\"y\")\n",
    "        tree.configure(yscrollcommand=vsb.set)\n",
    "        \n",
    "        # Add horizontal scrollbar\n",
    "        hsb = ttk.Scrollbar(tree_frame, orient=\"horizontal\", command=tree.xview)\n",
    "        hsb.pack(side=\"bottom\", fill=\"x\")\n",
    "        tree.configure(xscrollcommand=hsb.set)\n",
    "        \n",
    "        # Pack tree\n",
    "        tree.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "        \n",
    "        # Load initial data\n",
    "        load_data(tree, attendance_file, date_combobox, name_combobox)\n",
    "        \n",
    "        # Add export button\n",
    "        export_button = tk.Button(attendance_window, text=\"Export to CSV\", \n",
    "                                                           command=lambda: export_data(tree))\n",
    "        export_button.pack(pady=10)\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_label = tk.Label(tree_frame, text=f\"Error loading attendance data: {str(e)}\", fg=\"red\")\n",
    "        error_label.pack(pady=20)\n",
    "\n",
    "def load_data(tree, attendance_file, date_combobox=None, name_combobox=None):\n",
    "    \"\"\"Load attendance data into the treeview\"\"\"\n",
    "    # Clear existing data\n",
    "    for item in tree.get_children():\n",
    "        tree.delete(item)\n",
    "    \n",
    "    # Clear and configure columns\n",
    "    tree[\"columns\"] = []\n",
    "    tree[\"show\"] = \"headings\"\n",
    "    \n",
    "    try:\n",
    "        # Load the attendance data\n",
    "        df = pd.read_csv(attendance_file)\n",
    "        \n",
    "        # Configure columns based on DataFrame\n",
    "        columns = list(df.columns)\n",
    "        tree[\"columns\"] = columns\n",
    "        \n",
    "        # Set column headings and widths\n",
    "        for col in columns:\n",
    "            tree.heading(col, text=col, anchor=\"w\")\n",
    "            # Determine column width based on content\n",
    "            col_width = max(len(str(col)) * 10, df[col].astype(str).str.len().max() * 10)\n",
    "            tree.column(col, width=min(col_width, 200), anchor=\"w\")\n",
    "        \n",
    "        # Insert data\n",
    "        for idx, row in df.iterrows():\n",
    "            values = row.tolist()\n",
    "            tree.insert(\"\", \"end\", values=values)\n",
    "        \n",
    "        # Update date and name filter options if comboboxes are provided\n",
    "        if date_combobox is not None and 'Date' in df.columns:\n",
    "            dates = sorted(df['Date'].unique().tolist())\n",
    "            date_combobox['values'] = [''] + dates\n",
    "        \n",
    "        if name_combobox is not None and 'Name' in df.columns:\n",
    "            names = sorted(df['Name'].unique().tolist())\n",
    "            name_combobox['values'] = [''] + names\n",
    "            \n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Failed to load attendance data: {str(e)}\")\n",
    "\n",
    "def apply_filters(tree, attendance_file, date_filter=None, name_filter=None, search_text=None):\n",
    "    \"\"\"Apply filters to the attendance data\"\"\"\n",
    "    # Clear existing data\n",
    "    for item in tree.get_children():\n",
    "        tree.delete(item)\n",
    "    \n",
    "    try:\n",
    "        # Load the attendance data\n",
    "        df = pd.read_csv(attendance_file)\n",
    "        \n",
    "        # Apply date filter if specified\n",
    "        if date_filter and date_filter != '':\n",
    "            df = df[df['Date'] == date_filter]\n",
    "        \n",
    "        # Apply name filter if specified\n",
    "        if name_filter and name_filter != '':\n",
    "            df = df[df['Name'] == name_filter]\n",
    "        \n",
    "        # Apply search filter if specified\n",
    "        if search_text and search_text != '':\n",
    "            # Search in all columns\n",
    "            mask = pd.DataFrame(False, index=df.index, columns=['match'])\n",
    "            for col in df.columns:\n",
    "                mask['match'] |= df[col].astype(str).str.contains(search_text, case=False, na=False)\n",
    "            df = df[mask['match']]\n",
    "        \n",
    "        # Insert filtered data\n",
    "        for idx, row in df.iterrows():\n",
    "            values = row.tolist()\n",
    "            tree.insert(\"\", \"end\", values=values)\n",
    "            \n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Failed to apply filters: {str(e)}\")\n",
    "\n",
    "def export_data(tree):\n",
    "    \"\"\"Export currently displayed data to CSV\"\"\"\n",
    "    file_path = filedialog.asksaveasfilename(\n",
    "        defaultextension='.csv',\n",
    "        filetypes=[(\"CSV files\", \"*.csv\"), (\"All files\", \"*.*\")],\n",
    "        title=\"Export Attendance Data\"\n",
    "    )\n",
    "    \n",
    "    if not file_path:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Get column headers\n",
    "        columns = tree[\"columns\"]\n",
    "        \n",
    "        # Get all rows\n",
    "        data = []\n",
    "        for item in tree.get_children():\n",
    "            values = tree.item(item)['values']\n",
    "            data.append(values)\n",
    "        \n",
    "        # Create DataFrame and save to CSV\n",
    "        df = pd.DataFrame(data, columns=columns)\n",
    "        df.to_csv(file_path, index=False)\n",
    "        \n",
    "        messagebox.showinfo(\"Export Successful\", f\"Data exported to {file_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Export Error\", f\"Failed to export data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04443aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_gui(system):\n",
    "    \"\"\"Start the main GUI for the face attendance system\"\"\"\n",
    "    # Create the main window\n",
    "    root = Tk()\n",
    "    root.title(\"Advanced Face Attendance System\")\n",
    "    root.geometry(\"800x600\")\n",
    "    \n",
    "    # Set icon (if available)\n",
    "    try:\n",
    "        root.iconbitmap(\"icon.ico\")  # Replace with your icon path\n",
    "    except:\n",
    "        pass  # Icon file not available\n",
    "    \n",
    "    # Create tabs\n",
    "    tab_control = ttk.Notebook(root)\n",
    "    \n",
    "    # Tab 1: Dataset Management\n",
    "    tab_dataset = ttk.Frame(tab_control)\n",
    "    tab_control.add(tab_dataset, text=\"Dataset Management\")\n",
    "    \n",
    "    # Tab 2: Training & Recognition\n",
    "    tab_recognition = ttk.Frame(tab_control)\n",
    "    tab_control.add(tab_recognition, text=\"Training & Recognition\")\n",
    "    \n",
    "    # Tab 3: Settings\n",
    "    tab_settings = ttk.Frame(tab_control)\n",
    "    tab_control.add(tab_settings, text=\"Settings\")\n",
    "    \n",
    "    tab_control.pack(expand=1, fill=\"both\")\n",
    "    \n",
    "    # Status bar\n",
    "    status_frame = Frame(root, relief=tk.SUNKEN, bd=1)\n",
    "    status_frame.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "    \n",
    "    status_label = Label(status_frame, text=\"Ready\", anchor=tk.W, padx=5)\n",
    "    status_label.pack(side=tk.LEFT, fill=tk.X)\n",
    "    \n",
    "    # Function to update status\n",
    "    def update_status(message):\n",
    "        status_label.config(text=message)\n",
    "        root.update_idletasks()\n",
    "    \n",
    "    # Set status callback\n",
    "    system.set_status_callback(update_status)\n",
    "    \n",
    "    # ===== TAB 1: DATASET MANAGEMENT =====\n",
    "    # Name entry\n",
    "    Label(tab_dataset, text=\"Person Name:\").grid(row=0, column=0, padx=10, pady=10, sticky=\"w\")\n",
    "    name_entry = Entry(tab_dataset, width=30)\n",
    "    name_entry.grid(row=0, column=1, padx=10, pady=10, sticky=\"w\")\n",
    "    \n",
    "    # Number of samples\n",
    "    Label(tab_dataset, text=\"Number of Samples:\").grid(row=1, column=0, padx=10, pady=10, sticky=\"w\")\n",
    "    samples_var = tk.StringVar(value=\"10\")\n",
    "    samples_entry = Entry(tab_dataset, textvariable=samples_var, width=10)\n",
    "    samples_entry.grid(row=1, column=1, padx=10, pady=10, sticky=\"w\")\n",
    "    \n",
    "    # Capture faces button\n",
    "    def capture_webcam():\n",
    "        try:\n",
    "            num_samples = int(samples_var.get())\n",
    "            if num_samples <= 0:\n",
    "                update_status(\"[ERROR] Number of samples must be positive\")\n",
    "                return\n",
    "            create_dataset_from_webcam(DATASET_PATH, name_entry.get().strip(), num_samples, 1.0, update_status)\n",
    "        except ValueError:\n",
    "            update_status(\"[ERROR] Invalid number of samples\")\n",
    "\n",
    "    Button(tab_dataset, text=\"Capture via Webcam\", width=20,\n",
    "           command=capture_webcam).grid(row=2, column=0, padx=10, pady=10)\n",
    "    \n",
    "    # Add external images button\n",
    "    Button(tab_dataset, text=\"Add External Images\", width=20,\n",
    "           command=lambda: add_external_images(DATASET_PATH, name_entry.get().strip(), update_status)).grid(row=2, column=1, padx=10, pady=10)\n",
    "    \n",
    "    # View dataset button\n",
    "    Button(tab_dataset, text=\"View Dataset\", width=20,\n",
    "           command=lambda: os.startfile(DATASET_PATH) if os.name == 'nt' else \n",
    "                          os.system(f'xdg-open \"{DATASET_PATH}\"')).grid(row=3, column=0, padx=10, pady=10)\n",
    "    \n",
    "    # Delete person button\n",
    "    def delete_person():\n",
    "        \"\"\"Delete a person's dataset\"\"\"\n",
    "        name = name_entry.get().strip()\n",
    "        if not name:\n",
    "            update_status(\"[ERROR] Please enter a name\")\n",
    "            return\n",
    "        \n",
    "        person_dir = os.path.join(DATASET_PATH, name)\n",
    "        if os.path.exists(person_dir):\n",
    "            try:\n",
    "                shutil.rmtree(person_dir)\n",
    "                update_status(f\"[INFO] Successfully deleted dataset for {name}\")\n",
    "            except Exception as e:\n",
    "                update_status(f\"[ERROR] Failed to delete dataset: {str(e)}\")\n",
    "        else:\n",
    "            update_status(f\"[ERROR] No dataset found for {name}\")\n",
    "\n",
    "    Button(tab_dataset, text=\"Delete Person\", width=20,\n",
    "           command=delete_person).grid(row=3, column=1, padx=10, pady=10)\n",
    "\n",
    "    # ===== TAB 2: TRAINING & RECOGNITION =====\n",
    "    # Train model button\n",
    "    Button(tab_recognition, text=\"Train Model\", width=20,\n",
    "           command=system.train_model).grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "    # Start attendance button\n",
    "    Button(tab_recognition, text=\"Start Attendance\", width=20,\n",
    "           command=system.run_real_time_attendance).grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "    # Stop attendance button\n",
    "    Button(tab_recognition, text=\"Stop Attendance\", width=20,\n",
    "           command=system.stop_attendance).grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "    # View attendance button\n",
    "    Button(tab_recognition, text=\"View Attendance\", width=20,\n",
    "           command=lambda: show_attendance(ATTENDANCE_FILE)).grid(row=2, column=0, padx=10, pady=10)\n",
    "\n",
    "    # View log button\n",
    "    Button(tab_recognition, text=\"View Log\", width=20,\n",
    "           command=lambda: os.startfile(LOG_FILE) if os.name == 'nt' else \n",
    "                          os.system(f'xdg-open \"{LOG_FILE}\"')).grid(row=2, column=1, padx=10, pady=10)\n",
    "\n",
    "    # ===== TAB 3: SETTINGS =====\n",
    "    # Confidence threshold\n",
    "    Label(tab_settings, text=\"Confidence Threshold (0-100):\").grid(row=0, column=0, padx=10, pady=10, sticky=\"w\")\n",
    "    threshold_var = tk.StringVar(value=str(system.confidence_threshold))\n",
    "    threshold_entry = Entry(tab_settings, textvariable=threshold_var, width=10)\n",
    "    threshold_entry.grid(row=0, column=1, padx=10, pady=10, sticky=\"w\")\n",
    "\n",
    "    # Set threshold button\n",
    "    Button(tab_settings, text=\"Set Threshold\", width=20,\n",
    "           command=lambda: system.set_confidence_threshold(threshold_var.get())).grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "    # Clear attendance button\n",
    "    def clear_attendance():\n",
    "        \"\"\"Clear all attendance records\"\"\"\n",
    "        if messagebox.askyesno(\"Confirm\", \"Are you sure you want to clear all attendance records?\"):\n",
    "            try:\n",
    "                if os.path.exists(ATTENDANCE_FILE):\n",
    "                    os.remove(ATTENDANCE_FILE)\n",
    "                    update_status(\"[INFO] Attendance records cleared\")\n",
    "                else:\n",
    "                    update_status(\"[INFO] No attendance records to clear\")\n",
    "            except Exception as e:\n",
    "                update_status(f\"[ERROR] Failed to clear attendance: {str(e)}\")\n",
    "\n",
    "    Button(tab_settings, text=\"Clear Attendance\", width=20,\n",
    "           command=clear_attendance).grid(row=2, column=0, padx=10, pady=10)\n",
    "\n",
    "    # Clear log button\n",
    "    def clear_log():\n",
    "        \"\"\"Clear the system log\"\"\"\n",
    "        if messagebox.askyesno(\"Confirm\", \"Are you sure you want to clear the system log?\"):\n",
    "            try:\n",
    "                if os.path.exists(LOG_FILE):\n",
    "                    open(LOG_FILE, 'w').close()\n",
    "                    update_status(\"[INFO] System log cleared\")\n",
    "                else:\n",
    "                    update_status(\"[INFO] No log file to clear\")\n",
    "            except Exception as e:\n",
    "                update_status(f\"[ERROR] Failed to clear log: {str(e)}\")\n",
    "\n",
    "    Button(tab_settings, text=\"Clear Log\", width=20,\n",
    "           command=clear_log).grid(row=2, column=1, padx=10, pady=10)\n",
    "\n",
    "    # Make window responsive\n",
    "    for i in range(4):\n",
    "        tab_dataset.grid_rowconfigure(i, weight=1)\n",
    "        tab_recognition.grid_rowconfigure(i, weight=1)\n",
    "        tab_settings.grid_rowconfigure(i, weight=1)\n",
    "    for i in range(2):\n",
    "        tab_dataset.grid_columnconfigure(i, weight=1)\n",
    "        tab_recognition.grid_columnconfigure(i, weight=1)\n",
    "        tab_settings.grid_columnconfigure(i, weight=1)\n",
    "\n",
    "    # Start the main loop\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b718013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-20 15:27:40] [INFO] Training model...\n",
      "[2025-04-20 15:27:40] [INFO] Collected 10 images for Chetan\n",
      "[2025-04-20 15:27:40] [INFO] Model trained successfully with 10 images.\n",
      "[2025-04-20 15:27:45] [INFO] Started real-time attendance monitoring\n",
      "[2025-04-20 15:27:45] [INFO] Model and labels loaded successfully.\n",
      "[2025-04-20 15:27:46] [INFO] Created attendance file and marked Chetan\n",
      "[2025-04-20 15:28:26] [INFO] Attendance monitoring stopped\n",
      "[2025-04-20 15:28:49] [INFO] Recognition threshold set to 50.0\n",
      "[2025-04-20 15:29:21] [INFO] Training model...\n",
      "[2025-04-20 15:29:21] [INFO] Collected 10 images for Chetan\n",
      "[2025-04-20 15:29:21] [INFO] Collected 3 images for Chirag\n",
      "[2025-04-20 15:29:21] [INFO] Model trained successfully with 13 images.\n",
      "[2025-04-20 15:29:24] [INFO] Started real-time attendance monitoring\n",
      "[2025-04-20 15:29:24] [INFO] Model and labels loaded successfully.\n",
      "[2025-04-20 15:29:51] [INFO] Attendance monitoring stopped\n",
      "[2025-04-20 15:29:57] [INFO] Training model...\n",
      "[2025-04-20 15:29:57] [INFO] Collected 10 images for Chetan\n",
      "[2025-04-20 15:29:57] [INFO] Collected 3 images for Chirag\n",
      "[2025-04-20 15:29:57] [INFO] Model trained successfully with 13 images.\n",
      "[2025-04-20 15:30:00] [INFO] Attendance monitoring is not running\n",
      "[2025-04-20 15:30:03] [INFO] Started real-time attendance monitoring\n",
      "[2025-04-20 15:30:04] [INFO] Model and labels loaded successfully.\n",
      "[2025-04-20 15:30:44] [INFO] Attendance monitoring stopped\n",
      "[2025-04-20 15:31:24] [INFO] Recognition threshold set to 60.0\n",
      "[2025-04-20 15:32:47] [INFO] Training model...\n",
      "[2025-04-20 15:32:47] [INFO] Collected 10 images for Chetan\n",
      "[2025-04-20 15:32:47] [INFO] Model trained successfully with 10 images.\n",
      "[2025-04-20 15:32:49] [INFO] Started real-time attendance monitoring\n",
      "[2025-04-20 15:32:49] [INFO] Model and labels loaded successfully.\n",
      "[2025-04-20 15:32:53] [INFO] Created attendance file and marked Chetan\n",
      "[2025-04-20 15:33:17] [INFO] Attendance monitoring stopped\n",
      "[2025-04-20 15:33:31] [INFO] Recognition threshold set to 25.0\n",
      "[2025-04-20 15:33:35] [INFO] Started real-time attendance monitoring\n",
      "[2025-04-20 15:33:35] [INFO] Model and labels loaded successfully.\n",
      "[2025-04-20 15:34:04] [INFO] Attendance monitoring stopped\n",
      "[2025-04-20 15:34:05] [INFO] Training model...\n",
      "[2025-04-20 15:34:05] [INFO] Collected 10 images for Chetan\n",
      "[2025-04-20 15:34:05] [INFO] Model trained successfully with 10 images.\n",
      "[2025-04-20 15:34:08] [INFO] Started real-time attendance monitoring\n",
      "[2025-04-20 15:34:08] [INFO] Model and labels loaded successfully.\n",
      "[2025-04-20 15:34:24] [INFO] Attendance monitoring stopped\n",
      "[2025-04-20 15:34:29] [INFO] Started real-time attendance monitoring\n",
      "[2025-04-20 15:34:29] [INFO] Model and labels loaded successfully.\n",
      "[2025-04-20 15:34:35] [INFO] Attendance monitoring stopped\n",
      "[2025-04-20 15:34:51] [INFO] Started real-time attendance monitoring\n",
      "[2025-04-20 15:34:51] [INFO] Model and labels loaded successfully.\n",
      "[2025-04-20 15:35:04] [INFO] Attendance monitoring stopped\n",
      "[2025-04-20 15:35:06] [INFO] Attendance monitoring is not running\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Initialize the attendance system\n",
    "        attendance_system = CSVAttendanceSystem()\n",
    "        \n",
    "        # Start the GUI\n",
    "        start_gui(attendance_system)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to start application: {str(e)}\")\n",
    "        messagebox.showerror(\"Startup Error\", f\"Failed to start application: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
