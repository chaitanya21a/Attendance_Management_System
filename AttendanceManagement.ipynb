{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17906486",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ultralytics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpicamera\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PiCamera\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpicamera\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PiRGBArray\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import tkinter as tk\n",
    "from tkinter import Tk, Label, Entry, Button, filedialog, messagebox, Frame, ttk\n",
    "import shutil\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "import csv\n",
    "from ultralytics import YOLO\n",
    "from picamera import PiCamera\n",
    "from picamera.array import PiRGBArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a70c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATASET_PATH = 'dataset'\n",
    "TRAINER_PATH = 'trainer'\n",
    "MODEL_FILE = os.path.join(TRAINER_PATH, 'trainer.yml')\n",
    "ATTENDANCE_FILE = 'attendance.csv'\n",
    "LOG_FILE = 'system_log.txt'\n",
    "FRAME_QUEUE_SIZE = 5\n",
    "DEFAULT_CONFIDENCE_THRESHOLD = 85\n",
    "DEFAULT_NUM_SAMPLES = 10\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(DATASET_PATH, exist_ok=True)\n",
    "os.makedirs(TRAINER_PATH, exist_ok=True)\n",
    "\n",
    "# Initialize YOLO face detection\n",
    "yolo_model = YOLO('face_yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7018dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_activity(message):\n",
    "    \"\"\"Log activity with timestamp\"\"\"\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    log_message = f\"[{timestamp}] {message}\\n\"\n",
    "    try:\n",
    "        with open(LOG_FILE, 'a') as f:\n",
    "            f.write(log_message)\n",
    "    except Exception as e:\n",
    "        print(f\"Log write error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c0b519",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVAttendanceSystem:\n",
    "    def __init__(self, dataset_path=DATASET_PATH, model_file=MODEL_FILE, attendance_file=ATTENDANCE_FILE):\n",
    "        self.DATASET_PATH = dataset_path\n",
    "        self.MODEL_FILE = model_file\n",
    "        self.ATTENDANCE_FILE = attendance_file\n",
    "        self.LOG_FILE = LOG_FILE\n",
    "        self.DEFAULT_NUM_SAMPLES = DEFAULT_NUM_SAMPLES\n",
    "        self.DEFAULT_CONFIDENCE_THRESHOLD = DEFAULT_CONFIDENCE_THRESHOLD\n",
    "        self.recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "        self.yolo_model = yolo_model\n",
    "        self.labels = {}\n",
    "        self.confidence_threshold = DEFAULT_CONFIDENCE_THRESHOLD\n",
    "        self.status_callback = None\n",
    "        self.frame_queue = queue.Queue(maxsize=FRAME_QUEUE_SIZE)\n",
    "        self.attendance_thread = None\n",
    "        self.stop_flag = False\n",
    "\n",
    "    def set_status_callback(self, callback):\n",
    "        self.status_callback = callback\n",
    "\n",
    "    def update_status(self, message):\n",
    "        if self.status_callback:\n",
    "            self.status_callback(message)\n",
    "        log_activity(message)\n",
    "\n",
    "    def collect_training_data(self):\n",
    "        faces, ids = [], []\n",
    "        label_id = 0\n",
    "        self.labels = {}\n",
    "\n",
    "        if not os.path.exists(self.DATASET_PATH):\n",
    "            self.update_status(\"[ERROR] Dataset path does not exist\")\n",
    "            return faces, ids\n",
    "\n",
    "        for person_name in os.listdir(self.DATASET_PATH):\n",
    "            person_dir = os.path.join(self.DATASET_PATH, person_name)\n",
    "            if not os.path.isdir(person_dir):\n",
    "                continue\n",
    "\n",
    "            self.labels[label_id] = person_name\n",
    "            image_count = 0\n",
    "\n",
    "            for img_file in os.listdir(person_dir):\n",
    "                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    continue\n",
    "\n",
    "                img_path = os.path.join(person_dir, img_file)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if img is None:\n",
    "                    self.update_status(f\"[WARNING] Could not read image: {img_path}\")\n",
    "                    continue\n",
    "\n",
    "                img = cv2.resize(img, (100, 100))\n",
    "                faces.append(img)\n",
    "                ids.append(label_id)\n",
    "                image_count += 1\n",
    "\n",
    "            self.update_status(f\"[INFO] Collected {image_count} images for {person_name}\")\n",
    "            label_id += 1\n",
    "\n",
    "        try:\n",
    "            with open(os.path.join(TRAINER_PATH, 'labels.csv'), 'w', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(['ID', 'Name'])\n",
    "                for lid, name in self.labels.items():\n",
    "                    writer.writerow([lid, name])\n",
    "        except Exception as e:\n",
    "            self.update_status(f\"[ERROR] Failed to save labels: {e}\")\n",
    "\n",
    "        return faces, ids\n",
    "\n",
    "    def train_model(self):\n",
    "        self.update_status(\"[INFO] Training model...\")\n",
    "        faces, ids = self.collect_training_data()\n",
    "\n",
    "        if not faces:\n",
    "            self.update_status(\"[ERROR] No training data found\")\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            self.recognizer.train(faces, np.array(ids))\n",
    "            self.recognizer.save(self.MODEL_FILE)\n",
    "            self.update_status(f\"[INFO] Model trained with {len(faces)} images\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            self.update_status(f\"[ERROR] Training failed: {e}\")\n",
    "            return False\n",
    "\n",
    "    def load_model(self):\n",
    "        try:\n",
    "            if not os.path.exists(self.MODEL_FILE):\n",
    "                self.update_status(\"[ERROR] Model file not found\")\n",
    "                return False\n",
    "\n",
    "            self.recognizer.read(self.MODEL_FILE)\n",
    "            self.labels = {}\n",
    "            labels_file = os.path.join(TRAINER_PATH, 'labels.csv')\n",
    "\n",
    "            if os.path.exists(labels_file):\n",
    "                df = pd.read_csv(labels_file)\n",
    "                self.labels = dict(zip(df['ID'], df['Name']))\n",
    "                self.update_status(\"[INFO] Model and labels loaded\")\n",
    "                return True\n",
    "            else:\n",
    "                self.update_status(\"[ERROR] Labels file not found\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            self.update_status(f\"[ERROR] Failed to load model: {e}\")\n",
    "            return False\n",
    "\n",
    "    def mark_attendance(self, name):\n",
    "        now = datetime.now()\n",
    "        date, time_str = now.strftime('%Y-%m-%d'), now.strftime('%H:%M:%S')\n",
    "        try:\n",
    "            df = pd.DataFrame([[name, date, time_str]], columns=['Name', 'Date', 'Time'])\n",
    "            if os.path.exists(self.ATTENDANCE_FILE):\n",
    "                existing_df = pd.read_csv(self.ATTENDANCE_FILE)\n",
    "                if not existing_df[(existing_df['Name'] == name) & (existing_df['Date'] == date)].empty:\n",
    "                    self.update_status(f\"[INFO] {name} already marked today\")\n",
    "                    return False\n",
    "                df.to_csv(self.ATTENDANCE_FILE, mode='a', header=False, index=False)\n",
    "            else:\n",
    "                df.to_csv(self.ATTENDANCE_FILE, index=False)\n",
    "            self.update_status(f\"[INFO] Marked attendance for {name}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            self.update_status(f\"[ERROR] Attendance marking failed: {e}\")\n",
    "            return False\n",
    "\n",
    "    def set_confidence_threshold(self, threshold):\n",
    "        try:\n",
    "            threshold = float(threshold)\n",
    "            if 0 <= threshold <= 100:\n",
    "                self.confidence_threshold = threshold\n",
    "                self.update_status(f\"[INFO] Threshold set to {threshold}\")\n",
    "                return True\n",
    "            self.update_status(\"[ERROR] Threshold must be 0-100\")\n",
    "            return False\n",
    "        except ValueError:\n",
    "            self.update_status(\"[ERROR] Invalid threshold value\")\n",
    "            return False\n",
    "\n",
    "    def test_recognition(self, image_path):\n",
    "        self.update_status(\"[INFO] Testing recognition...\")\n",
    "        if not self.load_model():\n",
    "            self.update_status(\"[ERROR] Model not loaded\")\n",
    "            return\n",
    "\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            self.update_status(f\"[ERROR] Could not read image: {image_path}\")\n",
    "            return\n",
    "\n",
    "        if img.shape[0] > 480 or img.shape[1] > 640:\n",
    "            img = cv2.resize(img, (320, 240))\n",
    "\n",
    "        rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        gray = clahe.apply(gray)\n",
    "\n",
    "        results = self.yolo_model(rgb_img, conf=0.3, iou=0.7)\n",
    "        if not results or not results[0].boxes:\n",
    "            self.update_status(\"[WARNING] No face detected\")\n",
    "            return\n",
    "\n",
    "        for box in results[0].boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            face_gray = gray[y1:y2, x1:x2]\n",
    "            if face_gray.size == 0 or face_gray.shape[0] < 10 or face_gray.shape[1] < 10:\n",
    "                self.update_status(\"[WARNING] Invalid face region\")\n",
    "                continue\n",
    "            face_gray = cv2.resize(face_gray, (100, 100))\n",
    "            try:\n",
    "                label_id, confidence = self.recognizer.predict(face_gray)\n",
    "                name = self.labels.get(label_id, \"Unknown\")\n",
    "                self.update_status(f\"[INFO] Recognized: {name}, Confidence: {confidence}\")\n",
    "            except Exception as e:\n",
    "                self.update_status(f\"[ERROR] Recognition error: {e}\")\n",
    "\n",
    "    def run_real_time_attendance(self):\n",
    "        if self.attendance_thread and self.attendance_thread.is_alive():\n",
    "            self.update_status(\"[INFO] Attendance monitoring already running\")\n",
    "            return\n",
    "\n",
    "        self.stop_flag = False\n",
    "        self.attendance_thread = threading.Thread(target=self._attendance_thread)\n",
    "        self.attendance_thread.daemon = True\n",
    "        self.attendance_thread.start()\n",
    "        self.update_status(\"[INFO] Started real-time attendance\")\n",
    "\n",
    "    def stop_attendance(self):\n",
    "        if self.attendance_thread and self.attendance_thread.is_alive():\n",
    "            self.stop_flag = True\n",
    "            self.update_status(\"[INFO] Stopping attendance...\")\n",
    "        else:\n",
    "            self.update_status(\"[INFO] Attendance not running\")\n",
    "\n",
    "    def _attendance_thread(self):\n",
    "        if not self.load_model():\n",
    "            self.update_status(\"[ERROR] Model not loaded. Train first\")\n",
    "            return\n",
    "\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            self.update_status(\"[ERROR] Could not open webcam\")\n",
    "            return\n",
    "\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        cap.set(cv2.CAP_PROP_FPS, 15)\n",
    "\n",
    "        recognized = set()\n",
    "        try:\n",
    "            while not self.stop_flag:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    self.update_status(\"[WARNING] Failed to capture frame\")\n",
    "                    time.sleep(0.1)\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    self.frame_queue.put_nowait(frame)\n",
    "                except queue.Full:\n",
    "                    continue\n",
    "\n",
    "                if not self.frame_queue.empty():\n",
    "                    frame = self.frame_queue.get()\n",
    "                    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "                    gray = clahe.apply(gray)\n",
    "\n",
    "                    results = self.yolo_model(rgb_frame, conf=0.3, iou=0.7)\n",
    "                    if not results or not results[0].boxes:\n",
    "                        cv2.imshow(\"Attendance System\", frame)\n",
    "                        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                            self.stop_flag = True\n",
    "                        continue\n",
    "\n",
    "                    for box in results[0].boxes:\n",
    "                        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                        face_gray = gray[y1:y2, x1:x2]\n",
    "                        if face_gray.size == 0 or face_gray.shape[0] < 10 or face_gray.shape[1] < 10:\n",
    "                            continue\n",
    "                        face_gray = cv2.resize(face_gray, (100, 100))\n",
    "\n",
    "                        try:\n",
    "                            label_id, confidence = self.recognizer.predict(face_gray)\n",
    "                            if confidence < self.confidence_threshold:\n",
    "                                name = self.labels.get(label_id, \"Unknown\")\n",
    "                                if name != \"Unknown\" and name not in recognized:\n",
    "                                    if self.mark_attendance(name):\n",
    "                                        recognized.add(name)\n",
    "                                color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "                                label = f\"{name} ({int(confidence)})\" if name != \"Unknown\" else \"Unknown\"\n",
    "                            else:\n",
    "                                color = (0, 0, 255)\n",
    "                                label = \"Unknown\"\n",
    "\n",
    "                            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                            cv2.putText(frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "                        except Exception as e:\n",
    "                            self.update_status(f\"[ERROR] Recognition error: {e}\")\n",
    "\n",
    "                    cv2.imshow(\"Attendance System\", frame)\n",
    "                    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                        self.stop_flag = True\n",
    "                        break\n",
    "\n",
    "                time.sleep(0.02)\n",
    "        except Exception as e:\n",
    "            self.update_status(f\"[ERROR] Attendance error: {e}\")\n",
    "        finally:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            self.update_status(\"[INFO] Attendance stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dda8448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_from_picamera(dataset_path, name, num_samples=10, delay=0.5, update_callback=None, auto_capture=False, yolo_model=None):\n",
    "    if not name:\n",
    "        if update_callback:\n",
    "            update_callback(\"[ERROR] Invalid name\")\n",
    "        return False\n",
    "\n",
    "    if yolo_model is None:\n",
    "        if update_callback:\n",
    "            update_callback(\"[ERROR] YOLO model not provided\")\n",
    "        return False\n",
    "\n",
    "    person_dir = os.path.join(dataset_path, name)\n",
    "    os.makedirs(person_dir, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        camera = PiCamera()\n",
    "        camera.resolution = (640, 480)\n",
    "        camera.framerate = 15\n",
    "        rawCapture = PiRGBArray(camera, size=(640, 480))\n",
    "        time.sleep(0.1)  # Allow camera to warm up\n",
    "    except Exception as e:\n",
    "        if update_callback:\n",
    "            update_callback(f\"[ERROR] Could not initialize PiCamera: {e}\")\n",
    "        return False\n",
    "\n",
    "    count = 0\n",
    "    last_capture_time = time.time()\n",
    "\n",
    "    if update_callback:\n",
    "        update_callback(f\"[INFO] Capturing images for {name}. Press SPACE to capture{' or wait for auto-capture' if auto_capture else ''}, Q to quit...\")\n",
    "\n",
    "    try:\n",
    "        for frame in camera.capture_continuous(rawCapture, format=\"bgr\", use_video_port=True):\n",
    "            image = frame.array\n",
    "\n",
    "            rgb_frame = image.copy()\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "            gray = clahe.apply(gray)\n",
    "\n",
    "            height, width = image.shape[:2]\n",
    "            center_x, center_y = width // 2, height // 2\n",
    "            offset = min(width, height) // 4\n",
    "            cv2.rectangle(image, (center_x - offset, center_y - offset),\n",
    "                          (center_x + offset, center_y + offset), (255, 255, 0), 2)\n",
    "            cv2.putText(image, \"Position face in box\", (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(image, f\"Capturing: {count}/{num_samples}\", (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "            cv2.imshow(\"Capture Face\", image)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "            should_capture = False\n",
    "            current_time = time.time()\n",
    "            if key == ord(' '):\n",
    "                should_capture = True\n",
    "            elif auto_capture and (current_time - last_capture_time) >= delay:\n",
    "                should_capture = True\n",
    "\n",
    "            if should_capture:\n",
    "                results = yolo_model(rgb_frame, conf=0.3, iou=0.7)\n",
    "                if not results or not results[0].boxes:\n",
    "                    if update_callback:\n",
    "                        update_callback(\"[WARNING] No face detected\")\n",
    "                    rawCapture.truncate(0)\n",
    "                    continue\n",
    "\n",
    "                for box in results[0].boxes:\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    face = gray[y1:y2, x1:x2]\n",
    "                    if face.size == 0 or face.shape[0] < 10 or face.shape[1] < 10:\n",
    "                        if update_callback:\n",
    "                            update_callback(\"[WARNING] Invalid face region\")\n",
    "                        continue\n",
    "                    face = cv2.resize(face, (100, 100))\n",
    "                    file_path = os.path.join(person_dir, f\"{count}.jpg\")\n",
    "                    cv2.imwrite(file_path, face)\n",
    "                    count += 1\n",
    "                    last_capture_time = current_time\n",
    "                    if update_callback:\n",
    "                        update_callback(f\"[INFO] Captured: {count}/{num_samples}\")\n",
    "                    break\n",
    "\n",
    "            rawCapture.truncate(0)\n",
    "\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        if update_callback:\n",
    "            update_callback(f\"[ERROR] Capture error: {e}\")\n",
    "        return False\n",
    "\n",
    "    finally:\n",
    "        camera.close()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    if count > 0:\n",
    "        if update_callback:\n",
    "            update_callback(f\"[INFO] Captured {count} images for {name}\")\n",
    "        return True\n",
    "    if update_callback:\n",
    "        update_callback(\"[ERROR] No images captured\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca9afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_external_images(dataset_path, name, status_callback=None, yolo_model=None):\n",
    "    if not name:\n",
    "        if status_callback:\n",
    "            status_callback(\"[ERROR] Invalid name\")\n",
    "        return False\n",
    "\n",
    "    if yolo_model is None:\n",
    "        if status_callback:\n",
    "            status_callback(\"[ERROR] YOLO model not provided\")\n",
    "        return False\n",
    "\n",
    "    file_paths = filedialog.askopenfilenames(title=\"Select Face Images\", filetypes=[(\"Image Files\", \"*.jpg;*.jpeg;*.png\")])\n",
    "    if not file_paths:\n",
    "        if status_callback:\n",
    "            status_callback(\"[INFO] No files selected\")\n",
    "        return False\n",
    "\n",
    "    person_dir = os.path.join(dataset_path, name)\n",
    "    os.makedirs(person_dir, exist_ok=True)\n",
    "    count = len([f for f in os.listdir(person_dir) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    success_count = 0\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            img = cv2.imread(file_path)\n",
    "            if img is None or img.size == 0:\n",
    "                if status_callback:\n",
    "                    status_callback(f\"[ERROR] Invalid image: {os.path.basename(file_path)}\")\n",
    "                continue\n",
    "\n",
    "            if img.shape[0] > 480 or img.shape[1] > 640:\n",
    "                img = cv2.resize(img, (320, 240))\n",
    "\n",
    "            rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "            gray = clahe.apply(gray)\n",
    "\n",
    "            results = yolo_model(rgb_img, conf=0.3, iou=0.7)\n",
    "            if not results or not results[0].boxes:\n",
    "                if status_callback:\n",
    "                    status_callback(f\"[WARNING] No face in {os.path.basename(file_path)}\")\n",
    "                continue\n",
    "\n",
    "            for box in results[0].boxes:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                face = gray[y1:y2, x1:x2]\n",
    "                if face.size == 0 or face.shape[0] < 10 or face.shape[1] < 10:\n",
    "                    if status_callback:\n",
    "                        status_callback(f\"[WARNING] Invalid face region in {os.path.basename(file_path)}\")\n",
    "                    continue\n",
    "                face_resized = cv2.resize(face, (100, 100))\n",
    "                img_name = os.path.join(person_dir, f\"{count}.jpg\")\n",
    "                cv2.imwrite(img_name, face_resized)\n",
    "                if status_callback:\n",
    "                    status_callback(f\"[INFO] Processed: {os.path.basename(file_path)}\")\n",
    "                count += 1\n",
    "                success_count += 1\n",
    "                break\n",
    "\n",
    "        except Exception as e:\n",
    "            if status_callback:\n",
    "                status_callback(f\"[ERROR] Failed to process {os.path.basename(file_path)}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if status_callback:\n",
    "        status_callback(f\"[INFO] Processed {success_count}/{len(file_paths)} images for {name}\")\n",
    "    return success_count > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb75e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_attendance(attendance_file):\n",
    "    attendance_window = tk.Toplevel()\n",
    "    attendance_window.title(\"Attendance Records\")\n",
    "    attendance_window.geometry(\"700x500\")\n",
    "    main_frame = tk.Frame(attendance_window)\n",
    "    main_frame.pack(fill=\"both\", expand=True, padx=10, pady=10)\n",
    "\n",
    "    control_frame = tk.Frame(main_frame)\n",
    "    control_frame.pack(fill=\"x\", pady=(0, 10))\n",
    "    tk.Label(control_frame, text=\"Filter by date:\").pack(side=\"left\", padx=(0, 5))\n",
    "    date_var = tk.StringVar()\n",
    "    date_combobox = ttk.Combobox(control_frame, textvariable=date_var, width=15)\n",
    "    date_combobox.pack(side=\"left\", padx=(0, 10))\n",
    "    tk.Label(control_frame, text=\"Filter by name:\").pack(side=\"left\", padx=(10, 5))\n",
    "    name_var = tk.StringVar()\n",
    "    name_combobox = ttk.Combobox(control_frame, textvariable=name_var, width=15)\n",
    "    name_combobox.pack(side=\"left\")\n",
    "    tk.Label(control_frame, text=\"Search:\").pack(side=\"left\", padx=(10, 5))\n",
    "    search_var = tk.StringVar()\n",
    "    search_entry = tk.Entry(control_frame, textvariable=search_var, width=15)\n",
    "    search_entry.pack(side=\"left\")\n",
    "    tk.Button(control_frame, text=\"Search\", \n",
    "             command=lambda: apply_filters(tree, attendance_file, date_var.get(), name_var.get(), search_var.get())).pack(side=\"left\", padx=5)\n",
    "    tk.Button(control_frame, text=\"Reset\", \n",
    "             command=lambda: load_data(tree, attendance_file, date_combobox, name_combobox)).pack(side=\"left\")\n",
    "\n",
    "    tree_frame = tk.Frame(main_frame)\n",
    "    tree_frame.pack(fill=\"both\", expand=True)\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(attendance_file) or os.path.getsize(attendance_file) == 0:\n",
    "            tk.Label(tree_frame, text=\"No attendance records found\", fg=\"gray\").pack(pady=50)\n",
    "            return\n",
    "\n",
    "        tree = ttk.Treeview(tree_frame)\n",
    "        vsb = ttk.Scrollbar(tree_frame, orient=\"vertical\", command=tree.yview)\n",
    "        vsb.pack(side=\"right\", fill=\"y\")\n",
    "        tree.configure(yscrollcommand=vsb.set)\n",
    "        hsb = ttk.Scrollbar(tree_frame, orient=\"horizontal\", command=tree.xview)\n",
    "        hsb.pack(side=\"bottom\", fill=\"x\")\n",
    "        tree.configure(xscrollcommand=hsb.set)\n",
    "        tree.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "        load_data(tree, attendance_file, date_combobox, name_combobox)\n",
    "        tk.Button(attendance_window, text=\"Export to CSV\", command=lambda: export_data(tree)).pack(pady=10)\n",
    "    except Exception as e:\n",
    "        tk.Label(tree_frame, text=f\"Error loading data: {e}\", fg=\"red\").pack(pady=20)\n",
    "\n",
    "def load_data(tree, attendance_file, date_combobox=None, name_combobox=None):\n",
    "    for item in tree.get_children():\n",
    "        tree.delete(item)\n",
    "    tree[\"columns\"] = []\n",
    "    tree[\"show\"] = \"headings\"\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(attendance_file)\n",
    "        columns = list(df.columns)\n",
    "        tree[\"columns\"] = columns\n",
    "\n",
    "        for col in columns:\n",
    "            tree.heading(col, text=col, anchor=\"w\")\n",
    "            col_width = max(len(str(col)) * 10, df[col].astype(str).str.len().max() * 10)\n",
    "            tree.column(col, width=min(col_width, 200), anchor=\"w\")\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            tree.insert(\"\", \"end\", values=row.tolist())\n",
    "\n",
    "        if date_combobox is not None and 'Date' in df.columns:\n",
    "            date_combobox['values'] = [''] + sorted(df['Date'].unique().tolist())\n",
    "        if name_combobox is not None and 'Name' in df.columns:\n",
    "            name_combobox['values'] = [''] + sorted(df['Name'].unique().tolist())\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Failed to load data: {e}\")\n",
    "\n",
    "def apply_filters(tree, attendance_file, date_filter=None, name_filter=None, search_text=None):\n",
    "    for item in tree.get_children():\n",
    "        tree.delete(item)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(attendance_file)\n",
    "        if date_filter:\n",
    "            df = df[df['Date'] == date_filter]\n",
    "        if name_filter:\n",
    "            df = df[df['Name'] == name_filter]\n",
    "        if search_text:\n",
    "            mask = pd.DataFrame(False, index=df.index, columns=['match'])\n",
    "            for col in df.columns:\n",
    "                mask['match'] |= df[col].astype(str).str.contains(search_text, case=False, na=False)\n",
    "            df = df[mask['match']]\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            tree.insert(\"\", \"end\", values=row.tolist())\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Failed to apply filters: {e}\")\n",
    "\n",
    "def export_data(tree):\n",
    "    file_path = filedialog.asksaveasfilename(defaultextension='.csv', filetypes=[(\"CSV files\", \"*.csv\"), (\"All files\", \"*.*\")], title=\"Export Attendance Data\")\n",
    "    if not file_path:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        columns = tree[\"columns\"]\n",
    "        data = [tree.item(item)['values'] for item in tree.get_children()]\n",
    "        pd.DataFrame(data, columns=columns).to_csv(file_path, index=False)\n",
    "        messagebox.showinfo(\"Export Successful\", f\"Data exported to {file_path}\")\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Export Error\", f\"Failed to export: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae73210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_gui(system):\n",
    "    root = Tk()\n",
    "    root.title(\"Advanced Face Attendance System\")\n",
    "    root.geometry(\"800x600\")\n",
    "    try:\n",
    "        root.iconbitmap(\"icon.ico\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    tab_control = ttk.Notebook(root)\n",
    "    tab_dataset = ttk.Frame(tab_control)\n",
    "    tab_recognition = ttk.Frame(tab_control)\n",
    "    tab_settings = ttk.Frame(tab_control)\n",
    "    tab_control.add(tab_dataset, text=\"Dataset Management\")\n",
    "    tab_control.add(tab_recognition, text=\"Training & Recognition\")\n",
    "    tab_control.add(tab_settings, text=\"Settings\")\n",
    "    tab_control.pack(expand=1, fill=\"both\")\n",
    "\n",
    "    status_frame = Frame(root, relief=tk.SUNKEN, bd=1)\n",
    "    status_frame.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "    status_label = Label(status_frame, text=\"Ready\", anchor=tk.W, padx=5)\n",
    "    status_label.pack(side=tk.LEFT, fill=tk.X)\n",
    "\n",
    "    def update_status(message):\n",
    "        status_label.config(text=message)\n",
    "        root.update_idletasks()\n",
    "\n",
    "    system.set_status_callback(update_status)\n",
    "\n",
    "    tk.Label(tab_dataset, text=\"Person Name:\").grid(row=0, column=0, padx=10, pady=10, sticky=\"w\")\n",
    "    name_entry = tk.Entry(tab_dataset, width=30)\n",
    "    name_entry.grid(row=0, column=1, padx=10, pady=10, sticky=\"w\")\n",
    "    tk.Label(tab_dataset, text=\"Number of Samples:\").grid(row=1, column=0, padx=10, pady=10, sticky=\"w\")\n",
    "    samples_var = tk.StringVar(value=str(system.DEFAULT_NUM_SAMPLES))\n",
    "    samples_entry = tk.Entry(tab_dataset, textvariable=samples_var, width=10)\n",
    "    samples_entry.grid(row=1, column=1, padx=10, pady=10, sticky=\"w\")\n",
    "    auto_capture_var = tk.BooleanVar(value=False)\n",
    "    tk.Checkbutton(tab_dataset, text=\"Auto-capture faces\", variable=auto_capture_var).grid(row=1, column=2, padx=10, pady=10, sticky=\"w\")\n",
    "\n",
    "    def capture_webcam():\n",
    "        try:\n",
    "            num_samples = int(samples_var.get())\n",
    "            if num_samples <= 0:\n",
    "                update_status(\"[ERROR] Positive samples required\")\n",
    "                return\n",
    "            create_dataset_from_webcam(system.DATASET_PATH, name_entry.get().strip(), num_samples, 0.5, update_status, auto_capture=auto_capture_var.get(), yolo_model=system.yolo_model)\n",
    "        except ValueError:\n",
    "            update_status(\"[ERROR] Invalid samples number\")\n",
    "\n",
    "    tk.Button(tab_dataset, text=\"Capture via Webcam\", width=20, command=capture_webcam).grid(row=2, column=0, padx=10, pady=10)\n",
    "    tk.Button(tab_dataset, text=\"Add External Images\", width=20, \n",
    "              command=lambda: add_external_images(system.DATASET_PATH, name_entry.get().strip(), update_status, yolo_model=system.yolo_model)).grid(row=2, column=1, padx=10, pady=10)\n",
    "    tk.Button(tab_dataset, text=\"View Dataset\", width=20, \n",
    "              command=lambda: os.startfile(system.DATASET_PATH) if os.name == 'nt' else os.system(f'xdg-open \"{system.DATASET_PATH}\"')).grid(row=3, column=0, padx=10, pady=10)\n",
    "\n",
    "    def delete_person():\n",
    "        name = name_entry.get().strip()\n",
    "        if not name:\n",
    "            update_status(\"[ERROR] Enter a name\")\n",
    "            return\n",
    "        person_dir = os.path.join(system.DATASET_PATH, name)\n",
    "        if os.path.exists(person_dir):\n",
    "            try:\n",
    "                shutil.rmtree(person_dir)\n",
    "                update_status(f\"[INFO] Deleted dataset for {name}\")\n",
    "            except Exception as e:\n",
    "                update_status(f\"[ERROR] Delete failed: {e}\")\n",
    "        else:\n",
    "            update_status(f\"[ERROR] No dataset for {name}\")\n",
    "\n",
    "    tk.Button(tab_dataset, text=\"Delete Person\", width=20, command=delete_person).grid(row=3, column=1, padx=10, pady=10)\n",
    "\n",
    "    tk.Button(tab_recognition, text=\"Train Model\", width=20, command=system.train_model).grid(row=0, column=0, padx=10, pady=10)\n",
    "    tk.Button(tab_recognition, text=\"Start Attendance\", width=20, command=system.run_real_time_attendance).grid(row=1, column=0, padx=10, pady=10)\n",
    "    tk.Button(tab_recognition, text=\"Stop Attendance\", width=20, command=system.stop_attendance).grid(row=1, column=1, padx=10, pady=10)\n",
    "    tk.Button(tab_recognition, text=\"View Attendance\", width=20, command=lambda: show_attendance(system.ATTENDANCE_FILE)).grid(row=2, column=0, padx=10, pady=10)\n",
    "    tk.Button(tab_recognition, text=\"View Log\", width=20, \n",
    "              command=lambda: os.startfile(system.LOG_FILE) if os.name == 'nt' else os.system(f'xdg-open \"{system.LOG_FILE}\"')).grid(row=2, column=1, padx=10, pady=10)\n",
    "    tk.Button(tab_recognition, text=\"Test Image\", width=20, \n",
    "              command=lambda: system.test_recognition(filedialog.askopenfilename())).grid(row=3, column=0, padx=10, pady=10)\n",
    "\n",
    "    tk.Label(tab_settings, text=\"Confidence Threshold (0-100):\").grid(row=0, column=0, padx=10, pady=10, sticky=\"w\")\n",
    "    threshold_var = tk.StringVar(value=str(system.confidence_threshold))\n",
    "    threshold_entry = tk.Entry(tab_settings, textvariable=threshold_var, width=10)\n",
    "    threshold_entry.grid(row=0, column=1, padx=10, pady=10, sticky=\"w\")\n",
    "    tk.Button(tab_settings, text=\"Set Threshold\", width=20, \n",
    "              command=lambda: system.set_confidence_threshold(threshold_var.get())).grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "    def clear_attendance():\n",
    "        if messagebox.askyesno(\"Confirm\", \"Clear all attendance records?\"):\n",
    "            try:\n",
    "                if os.path.exists(system.ATTENDANCE_FILE):\n",
    "                    os.remove(system.ATTENDANCE_FILE)\n",
    "                    update_status(\"[INFO] Attendance cleared\")\n",
    "                else:\n",
    "                    update_status(\"[INFO] No attendance to clear\")\n",
    "            except Exception as e:\n",
    "                update_status(f\"[ERROR] Clear failed: {e}\")\n",
    "\n",
    "    tk.Button(tab_settings, text=\"Clear Attendance\", width=20, command=clear_attendance).grid(row=2, column=0, padx=10, pady=10)\n",
    "\n",
    "    def clear_log():\n",
    "        if messagebox.askyesno(\"Confirm\", \"Clear system log?\"):\n",
    "            try:\n",
    "                if os.path.exists(system.LOG_FILE):\n",
    "                    open(system.LOG_FILE, 'w').close()\n",
    "                    update_status(\"[INFO] Log cleared\")\n",
    "                else:\n",
    "                    update_status(\"[INFO] No log to clear\")\n",
    "            except Exception as e:\n",
    "                update_status(f\"[ERROR] Clear failed: {e}\")\n",
    "\n",
    "    tk.Button(tab_settings, text=\"Clear Log\", width=20, command=clear_log).grid(row=2, column=1, padx=10, pady=10)\n",
    "\n",
    "    for i in range(4):\n",
    "        tab_dataset.grid_rowconfigure(i, weight=1)\n",
    "        tab_recognition.grid_rowconfigure(i, weight=1)\n",
    "        tab_settings.grid_rowconfigure(i, weight=1)\n",
    "    for i in range(2):\n",
    "        tab_dataset.grid_columnconfigure(i, weight=1)\n",
    "        tab_recognition.grid_columnconfigure(i, weight=1)\n",
    "        tab_settings.grid_columnconfigure(i, weight=1)\n",
    "\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd6c151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 face, 44.5ms\n",
      "Speed: 1.7ms preprocess, 44.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.5ms\n",
      "Speed: 1.9ms preprocess, 32.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 36.6ms\n",
      "Speed: 1.3ms preprocess, 36.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.2ms\n",
      "Speed: 1.0ms preprocess, 34.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.1ms\n",
      "Speed: 1.7ms preprocess, 33.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.0ms\n",
      "Speed: 1.7ms preprocess, 32.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.6ms\n",
      "Speed: 1.3ms preprocess, 32.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 31.0ms\n",
      "Speed: 1.3ms preprocess, 31.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 28.3ms\n",
      "Speed: 1.6ms preprocess, 28.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 38.7ms\n",
      "Speed: 1.2ms preprocess, 38.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 38.9ms\n",
      "Speed: 3.9ms preprocess, 38.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 36.8ms\n",
      "Speed: 1.9ms preprocess, 36.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.2ms\n",
      "Speed: 1.7ms preprocess, 35.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.8ms\n",
      "Speed: 1.2ms preprocess, 34.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.5ms\n",
      "Speed: 1.2ms preprocess, 32.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.0ms\n",
      "Speed: 1.1ms preprocess, 35.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.9ms\n",
      "Speed: 1.1ms preprocess, 35.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.4ms\n",
      "Speed: 1.6ms preprocess, 32.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.6ms\n",
      "Speed: 1.3ms preprocess, 33.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.2ms\n",
      "Speed: 1.1ms preprocess, 35.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.8ms\n",
      "Speed: 1.3ms preprocess, 33.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 31.9ms\n",
      "Speed: 1.3ms preprocess, 31.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 36.2ms\n",
      "Speed: 1.0ms preprocess, 36.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 31.8ms\n",
      "Speed: 1.4ms preprocess, 31.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.6ms\n",
      "Speed: 1.0ms preprocess, 34.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.3ms\n",
      "Speed: 1.1ms preprocess, 34.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 30.1ms\n",
      "Speed: 1.5ms preprocess, 30.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.6ms\n",
      "Speed: 1.0ms preprocess, 32.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.9ms\n",
      "Speed: 1.0ms preprocess, 33.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 30.6ms\n",
      "Speed: 1.4ms preprocess, 30.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.3ms\n",
      "Speed: 1.4ms preprocess, 32.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 31.1ms\n",
      "Speed: 1.0ms preprocess, 31.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 29.8ms\n",
      "Speed: 1.5ms preprocess, 29.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.3ms\n",
      "Speed: 1.1ms preprocess, 33.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 30.7ms\n",
      "Speed: 1.4ms preprocess, 30.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 29.1ms\n",
      "Speed: 1.1ms preprocess, 29.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.0ms\n",
      "Speed: 1.0ms preprocess, 32.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.0ms\n",
      "Speed: 1.6ms preprocess, 35.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.3ms\n",
      "Speed: 1.1ms preprocess, 33.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.9ms\n",
      "Speed: 1.0ms preprocess, 33.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 31.9ms\n",
      "Speed: 1.0ms preprocess, 31.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.0ms\n",
      "Speed: 1.0ms preprocess, 32.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.2ms\n",
      "Speed: 1.3ms preprocess, 32.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.0ms\n",
      "Speed: 1.4ms preprocess, 35.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.3ms\n",
      "Speed: 1.0ms preprocess, 33.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.6ms\n",
      "Speed: 1.1ms preprocess, 33.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.4ms\n",
      "Speed: 1.2ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.7ms\n",
      "Speed: 1.0ms preprocess, 32.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.0ms\n",
      "Speed: 1.4ms preprocess, 34.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.1ms\n",
      "Speed: 1.4ms preprocess, 34.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.3ms\n",
      "Speed: 1.4ms preprocess, 34.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.9ms\n",
      "Speed: 1.1ms preprocess, 32.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.9ms\n",
      "Speed: 1.2ms preprocess, 35.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.8ms\n",
      "Speed: 1.0ms preprocess, 32.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.0ms\n",
      "Speed: 1.3ms preprocess, 32.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.6ms\n",
      "Speed: 1.0ms preprocess, 33.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.3ms\n",
      "Speed: 1.3ms preprocess, 33.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.8ms\n",
      "Speed: 1.1ms preprocess, 33.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.1ms\n",
      "Speed: 1.1ms preprocess, 35.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 31.1ms\n",
      "Speed: 1.0ms preprocess, 31.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.6ms\n",
      "Speed: 1.0ms preprocess, 32.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.7ms\n",
      "Speed: 1.2ms preprocess, 33.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.3ms\n",
      "Speed: 1.0ms preprocess, 32.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 27.2ms\n",
      "Speed: 1.5ms preprocess, 27.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.4ms\n",
      "Speed: 1.1ms preprocess, 33.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 30.6ms\n",
      "Speed: 1.0ms preprocess, 30.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.2ms\n",
      "Speed: 1.4ms preprocess, 32.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.2ms\n",
      "Speed: 1.5ms preprocess, 33.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.5ms\n",
      "Speed: 1.0ms preprocess, 35.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 50.0ms\n",
      "Speed: 1.1ms preprocess, 50.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.0ms\n",
      "Speed: 1.4ms preprocess, 34.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.5ms\n",
      "Speed: 1.3ms preprocess, 34.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.9ms\n",
      "Speed: 1.2ms preprocess, 35.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 36.8ms\n",
      "Speed: 1.4ms preprocess, 36.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.3ms\n",
      "Speed: 1.4ms preprocess, 34.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.0ms\n",
      "Speed: 1.0ms preprocess, 33.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 36.7ms\n",
      "Speed: 1.2ms preprocess, 36.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 31.7ms\n",
      "Speed: 1.3ms preprocess, 31.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.0ms\n",
      "Speed: 1.6ms preprocess, 34.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 31.7ms\n",
      "Speed: 1.1ms preprocess, 31.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.8ms\n",
      "Speed: 1.8ms preprocess, 32.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.0ms\n",
      "Speed: 1.0ms preprocess, 32.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.7ms\n",
      "Speed: 2.1ms preprocess, 33.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.0ms\n",
      "Speed: 1.1ms preprocess, 35.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 29.8ms\n",
      "Speed: 1.7ms preprocess, 29.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.9ms\n",
      "Speed: 1.5ms preprocess, 32.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.1ms\n",
      "Speed: 1.9ms preprocess, 35.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.3ms\n",
      "Speed: 1.1ms preprocess, 33.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 36.2ms\n",
      "Speed: 1.1ms preprocess, 36.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.0ms\n",
      "Speed: 1.2ms preprocess, 32.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 31.4ms\n",
      "Speed: 1.2ms preprocess, 31.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.9ms\n",
      "Speed: 1.4ms preprocess, 33.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.2ms\n",
      "Speed: 1.3ms preprocess, 34.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.8ms\n",
      "Speed: 1.1ms preprocess, 33.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.7ms\n",
      "Speed: 1.0ms preprocess, 34.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.7ms\n",
      "Speed: 1.2ms preprocess, 35.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.6ms\n",
      "Speed: 1.5ms preprocess, 32.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.2ms\n",
      "Speed: 1.1ms preprocess, 35.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.5ms\n",
      "Speed: 1.4ms preprocess, 33.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.7ms\n",
      "Speed: 1.6ms preprocess, 33.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.9ms\n",
      "Speed: 1.3ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 30.5ms\n",
      "Speed: 1.0ms preprocess, 30.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.8ms\n",
      "Speed: 1.0ms preprocess, 34.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.2ms\n",
      "Speed: 1.0ms preprocess, 35.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.4ms\n",
      "Speed: 1.2ms preprocess, 34.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.1ms\n",
      "Speed: 1.4ms preprocess, 33.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.2ms\n",
      "Speed: 1.6ms preprocess, 33.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.5ms\n",
      "Speed: 1.6ms preprocess, 33.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.7ms\n",
      "Speed: 1.3ms preprocess, 35.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.1ms\n",
      "Speed: 1.1ms preprocess, 33.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.9ms\n",
      "Speed: 1.5ms preprocess, 33.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.3ms\n",
      "Speed: 1.2ms preprocess, 35.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.7ms\n",
      "Speed: 1.1ms preprocess, 34.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.6ms\n",
      "Speed: 1.2ms preprocess, 34.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 36.8ms\n",
      "Speed: 2.1ms preprocess, 36.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.6ms\n",
      "Speed: 1.6ms preprocess, 34.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 38.9ms\n",
      "Speed: 1.5ms preprocess, 38.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.7ms\n",
      "Speed: 1.0ms preprocess, 32.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.2ms\n",
      "Speed: 1.4ms preprocess, 33.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.8ms\n",
      "Speed: 1.5ms preprocess, 32.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.0ms\n",
      "Speed: 1.0ms preprocess, 34.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.6ms\n",
      "Speed: 1.2ms preprocess, 35.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.8ms\n",
      "Speed: 1.1ms preprocess, 33.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.6ms\n",
      "Speed: 1.1ms preprocess, 34.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 39.1ms\n",
      "Speed: 1.0ms preprocess, 39.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.0ms\n",
      "Speed: 1.2ms preprocess, 33.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.9ms\n",
      "Speed: 1.4ms preprocess, 35.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.4ms\n",
      "Speed: 1.4ms preprocess, 33.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 31.7ms\n",
      "Speed: 1.3ms preprocess, 31.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.0ms\n",
      "Speed: 1.1ms preprocess, 35.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.4ms\n",
      "Speed: 1.5ms preprocess, 35.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.7ms\n",
      "Speed: 1.0ms preprocess, 33.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 26.9ms\n",
      "Speed: 1.1ms preprocess, 26.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.7ms\n",
      "Speed: 1.1ms preprocess, 34.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.2ms\n",
      "Speed: 1.3ms preprocess, 34.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.8ms\n",
      "Speed: 1.0ms preprocess, 35.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.5ms\n",
      "Speed: 1.2ms preprocess, 33.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.2ms\n",
      "Speed: 1.1ms preprocess, 34.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.3ms\n",
      "Speed: 1.4ms preprocess, 32.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.8ms\n",
      "Speed: 1.5ms preprocess, 32.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.6ms\n",
      "Speed: 1.3ms preprocess, 33.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.9ms\n",
      "Speed: 1.1ms preprocess, 35.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.6ms\n",
      "Speed: 1.8ms preprocess, 32.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.1ms\n",
      "Speed: 1.4ms preprocess, 35.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.0ms\n",
      "Speed: 1.4ms preprocess, 34.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.3ms\n",
      "Speed: 1.4ms preprocess, 32.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 31.7ms\n",
      "Speed: 1.3ms preprocess, 31.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 38.2ms\n",
      "Speed: 1.7ms preprocess, 38.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.8ms\n",
      "Speed: 1.1ms preprocess, 33.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.6ms\n",
      "Speed: 1.4ms preprocess, 35.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 31.9ms\n",
      "Speed: 1.0ms preprocess, 31.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.3ms\n",
      "Speed: 1.5ms preprocess, 34.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.0ms\n",
      "Speed: 1.6ms preprocess, 32.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.2ms\n",
      "Speed: 1.3ms preprocess, 35.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.2ms\n",
      "Speed: 1.4ms preprocess, 35.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.5ms\n",
      "Speed: 1.0ms preprocess, 35.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 31.5ms\n",
      "Speed: 1.0ms preprocess, 31.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.4ms\n",
      "Speed: 1.0ms preprocess, 35.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.7ms\n",
      "Speed: 1.0ms preprocess, 34.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.6ms\n",
      "Speed: 1.5ms preprocess, 35.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.2ms\n",
      "Speed: 1.4ms preprocess, 34.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.5ms\n",
      "Speed: 1.4ms preprocess, 35.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 36.4ms\n",
      "Speed: 1.0ms preprocess, 36.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 36.4ms\n",
      "Speed: 1.1ms preprocess, 36.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.4ms\n",
      "Speed: 1.4ms preprocess, 35.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 36.2ms\n",
      "Speed: 1.4ms preprocess, 36.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.8ms\n",
      "Speed: 1.0ms preprocess, 33.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 36.3ms\n",
      "Speed: 1.7ms preprocess, 36.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 31.9ms\n",
      "Speed: 1.0ms preprocess, 31.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.0ms\n",
      "Speed: 1.3ms preprocess, 34.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.1ms\n",
      "Speed: 1.2ms preprocess, 34.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 31.8ms\n",
      "Speed: 1.1ms preprocess, 31.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.5ms\n",
      "Speed: 1.4ms preprocess, 32.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.0ms\n",
      "Speed: 1.4ms preprocess, 35.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.0ms\n",
      "Speed: 1.4ms preprocess, 34.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.0ms\n",
      "Speed: 1.9ms preprocess, 33.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.1ms\n",
      "Speed: 1.0ms preprocess, 35.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 31.6ms\n",
      "Speed: 1.0ms preprocess, 31.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.3ms\n",
      "Speed: 1.4ms preprocess, 32.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.5ms\n",
      "Speed: 1.1ms preprocess, 32.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 30.7ms\n",
      "Speed: 1.2ms preprocess, 30.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.1ms\n",
      "Speed: 1.4ms preprocess, 35.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 29.7ms\n",
      "Speed: 1.3ms preprocess, 29.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.3ms\n",
      "Speed: 1.7ms preprocess, 34.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 38.1ms\n",
      "Speed: 1.3ms preprocess, 38.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.5ms\n",
      "Speed: 1.1ms preprocess, 32.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.7ms\n",
      "Speed: 1.1ms preprocess, 32.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.9ms\n",
      "Speed: 1.7ms preprocess, 33.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.5ms\n",
      "Speed: 1.1ms preprocess, 33.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.6ms\n",
      "Speed: 1.4ms preprocess, 34.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.2ms\n",
      "Speed: 1.4ms preprocess, 35.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.9ms\n",
      "Speed: 1.1ms preprocess, 34.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.3ms\n",
      "Speed: 1.0ms preprocess, 35.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.6ms\n",
      "Speed: 1.3ms preprocess, 35.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.4ms\n",
      "Speed: 1.4ms preprocess, 35.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.1ms\n",
      "Speed: 1.4ms preprocess, 35.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.8ms\n",
      "Speed: 1.5ms preprocess, 33.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 36.5ms\n",
      "Speed: 1.4ms preprocess, 36.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.5ms\n",
      "Speed: 1.3ms preprocess, 33.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.2ms\n",
      "Speed: 1.1ms preprocess, 32.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.8ms\n",
      "Speed: 1.1ms preprocess, 32.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 36.0ms\n",
      "Speed: 1.1ms preprocess, 36.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.4ms\n",
      "Speed: 1.0ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 36.0ms\n",
      "Speed: 1.1ms preprocess, 36.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.7ms\n",
      "Speed: 1.4ms preprocess, 34.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.7ms\n",
      "Speed: 1.4ms preprocess, 33.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 31.4ms\n",
      "Speed: 1.2ms preprocess, 31.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.2ms\n",
      "Speed: 1.4ms preprocess, 35.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.7ms\n",
      "Speed: 1.1ms preprocess, 33.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.2ms\n",
      "Speed: 1.5ms preprocess, 34.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 37.3ms\n",
      "Speed: 1.5ms preprocess, 37.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.4ms\n",
      "Speed: 1.1ms preprocess, 35.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.2ms\n",
      "Speed: 1.0ms preprocess, 33.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.8ms\n",
      "Speed: 1.2ms preprocess, 33.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 31.2ms\n",
      "Speed: 1.0ms preprocess, 31.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 36.7ms\n",
      "Speed: 1.4ms preprocess, 36.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.6ms\n",
      "Speed: 1.1ms preprocess, 33.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.9ms\n",
      "Speed: 1.1ms preprocess, 34.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.8ms\n",
      "Speed: 1.1ms preprocess, 32.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.2ms\n",
      "Speed: 1.2ms preprocess, 35.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 32.4ms\n",
      "Speed: 1.3ms preprocess, 32.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 34.8ms\n",
      "Speed: 1.0ms preprocess, 34.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 36.3ms\n",
      "Speed: 1.3ms preprocess, 36.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.6ms\n",
      "Speed: 1.3ms preprocess, 35.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 30.3ms\n",
      "Speed: 1.1ms preprocess, 30.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.1ms\n",
      "Speed: 1.5ms preprocess, 33.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 35.6ms\n",
      "Speed: 1.0ms preprocess, 35.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.8ms\n",
      "Speed: 1.6ms preprocess, 33.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 36.7ms\n",
      "Speed: 1.2ms preprocess, 36.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 36.0ms\n",
      "Speed: 1.4ms preprocess, 36.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 33.8ms\n",
      "Speed: 1.4ms preprocess, 33.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        attendance_system = CSVAttendanceSystem()\n",
    "        start_gui(attendance_system)\n",
    "    except Exception as e:\n",
    "        print(f\"Startup failed: {e}\")\n",
    "        messagebox.showerror(\"Startup Error\", f\"Startup failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
